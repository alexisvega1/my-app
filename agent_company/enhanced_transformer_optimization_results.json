{
  "best_config": {
    "learning_rate": 0.0005,
    "batch_size": 64,
    "effective_batch_size": 128,
    "hidden_size": 1024,
    "num_layers": 24,
    "num_heads": 8,
    "dropout_rate": 0.1,
    "weight_decay": 0.0001,
    "gradient_accumulation_steps": 2
  },
  "best_metrics": {
    "loss": 0.020477185103838186,
    "accuracy": 0.9475208068748318,
    "learning_rate": 0.000495,
    "batch_size": 64,
    "effective_batch_size": 128,
    "memory_usage_gb": 6.33197384513177,
    "gpu_utilization": 0.7265819777676639,
    "validation_loss": 0.022524903614222005,
    "validation_accuracy": 0.928570390737335
  },
  "convergence_analysis": {
    "total_iterations": 100,
    "final_loss": 0.020477185103838186,
    "final_accuracy": 0.9475208068748318,
    "loss_improvement": 0.5055242663937451,
    "accuracy_improvement": 0.3475208068748318,
    "lr_final": 0.000495,
    "lr_change": 0.901,
    "convergence_rate": 0.9544845219584707,
    "avg_gpu_utilization": 0.81259313302333,
    "final_gpu_utilization": 0.7265819777676639
  },
  "hyperparameter_importance": {
    "learning_rate": 0.5767106865641708,
    "batch_size": 0.19318961112819938,
    "hidden_size": 0.32376112964517867,
    "num_layers": 0.30883892328425866,
    "num_heads": 0.5021215998884379,
    "dropout_rate": 0.17475640101866421,
    "weight_decay": 0.11176752745557648,
    "gradient_accumulation_steps": 0.02261524470595677
  },
  "recommendations": [
    "\ud83d\ude80 Learning rate optimized for fast convergence",
    "\u26a1 Large effective batch size for training efficiency",
    "\u26a0\ufe0f GPU utilization could be improved",
    "\ud83c\udfaf Excellent convergence rate achieved",
    "\u2705 High accuracy achieved"
  ],
  "optimization_time": 0.00409388542175293,
  "cross_validation_scores": [
    0.5416157820333514,
    0.6478215060612792,
    0.6671907296974299,
    0.5884737098931151,
    0.6352884383382355,
    0.4160961009256949,
    0.6457085995007571,
    0.6864036810054942,
    0.7355800917638166,
    0.6995939566359944,
    0.7067287223449842,
    0.6243190749694275,
    0.5059189807687888,
    0.6709970089637748,
    0.46226633499840486,
    0.3837213578857393,
    0.5751441027315903,
    0.7324091275731669,
    0.6269989057444866,
    0.4316762191761995,
    0.7174476128127236,
    0.4211892863093873,
    0.4490010776553302,
    0.8101512320893307,
    0.38125862379583,
    0.47856172323918816,
    0.7653928367628349,
    0.717916158655591,
    0.7390530815219902,
    0.6527286923172082,
    0.6997700540376872,
    0.8356575459217609,
    0.7578888993725132,
    0.7950915800970871,
    0.5434858637412779,
    0.6739438109122933,
    0.41729751826428774,
    0.611216983859738,
    0.5613681097705577,
    0.8638590634661995,
    0.44131820908161323,
    0.459089580799942,
    0.7880492147866774,
    0.6411302298839257,
    0.5219462289094959,
    0.5457564143525709,
    0.6709918216540146,
    0.5938738782103486,
    0.5727930854095585,
    0.831974815933055,
    0.565852285749647,
    0.6870530079351088,
    0.6987453154328986,
    0.6947905879827471,
    0.7774972287247799,
    0.5009872438636336,
    0.6787648667407079,
    0.6650462400739326,
    0.5972283995411942,
    0.544098580617819,
    0.8097668240894181,
    0.6190408791264396,
    0.72491216325153,
    0.639786033724164,
    0.7948530826370538,
    0.652787944721439,
    0.604617183182622,
    0.6942692788908588,
    0.6731861771719766,
    0.6899894262095603,
    0.5228480309070083,
    0.38597405971982784,
    0.5664066941480289,
    0.8488982575620634,
    0.794283443140977,
    0.7375544658870026,
    0.37267959803445433,
    0.671800492519429,
    0.7730906532378296,
    0.8041865218816359,
    0.711165703666544,
    0.6465739537564903,
    0.5765974080251672,
    0.4670206907602488,
    0.6272488757515885,
    0.5210515452105536,
    0.4132383121128311,
    0.5338463678772056,
    0.6616664547206264,
    0.528636481709556,
    0.7033889357976629,
    0.5937008252399597,
    0.7350182355276159,
    0.7998273610891177,
    0.681231458819059,
    0.5257100712844894,
    0.7878473798199019,
    0.684264044112326,
    0.5861217208555748,
    0.7904094233152725
  ]
}